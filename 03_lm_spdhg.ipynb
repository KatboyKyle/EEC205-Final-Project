{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# PDHG and LM-SPHG to optimize the Poisson logL and total variation\n",
    "\n",
    "This example demonstrates the use of the primal dual hybrid gradient (PDHG) algorithm, \n",
    "the listmode stochastic PDHG (LM-SPDHG) to minimize the negative \n",
    "Poisson log-likelihood function combined with a total variation regularizer:\n",
    "\n",
    "\\begin{align}f(x) = \\sum_{i=1}^m \\bar{d}_i (x) - d_i \\log(\\bar{d}_i (x)) + \\beta \\|\\nabla x \\|_{1,2}\\end{align}\n",
    "\n",
    "subject to\n",
    "\n",
    "\\begin{align}x \\geq 0\\end{align}\n",
    "using the linear forward model\n",
    "\n",
    "\\begin{align}\\bar{d}(x) = A x + s\\end{align}\n",
    "\n",
    ".. tip::\n",
    "    parallelproj is python array API compatible meaning it supports different \n",
    "    array backends (e.g. numpy, cupy, torch, ...) and devices (CPU or GPU).\n",
    "    Choose your preferred array API ``xp`` and device ``dev`` below.\n",
    "\n",
    "<div class=\"alert alert-danger\"><h4>Warning</h4><p>Running this example using GPU arrays (e.g. using cupy as array backend) \n",
    "    is highly recommended due to \"longer\" execution times with CPU arrays</p></div>\n",
    "\n",
    "<img src=\"https://mybinder.org/badge_logo.svg\" target=\"https://mybinder.org/v2/gh/gschramm/parallelproj/master?labpath=examples\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\holot\\anaconda3\\Lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          -  -  -  -  -  -  -  -   -  -  -  -\n",
      "          P  A  R  A  L  L  E  L | P  R  O  J\n",
      "          -  -  -  -  -  -  -  -   -  -  -  -\n",
      "\n",
      "    =================================================\n",
      "\n",
      "         Please consider citing our publication\n",
      "      ---------------------------------------------\n",
      "      Georg Schramm and Kris Thielemans:\n",
      "      \"PARALLELPROJâ€”an open-source framework for\n",
      "       fast calculation of projections in\n",
      "       tomography\"\n",
      "      Front. Nucl. Med., 08 January 2024\n",
      "      Sec. PET and SPECT, Vol 3\n",
      "      https://doi.org/10.3389/fnume.2023.1324562\n",
      "\n",
      "    =================================================\n",
      " \n",
      "    parallelproj C    lib: C:\\Users\\holot\\anaconda3\\Library\\bin\\parallelproj_c.dll\n",
      "    parallelproj CUDA lib: C:\\Users\\holot\\anaconda3\\Library\\bin\\parallelproj_cuda.dll\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import array_api_compat.cupy as xp\n",
    "\n",
    "# import array_api_compat.numpy as xp\n",
    "# import array_api_compat.torch as xp\n",
    "\n",
    "import parallelproj\n",
    "from array_api_compat import to_device\n",
    "import array_api_compat.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# choose a device (CPU or CUDA GPU)\n",
    "if \"numpy\" in xp.__name__:\n",
    "    # using numpy, device must be cpu\n",
    "    dev = \"cpu\"\n",
    "elif \"cupy\" in xp.__name__:\n",
    "    # using cupy, only cuda devices are possible\n",
    "    dev = xp.cuda.Device(0)\n",
    "elif \"torch\" in xp.__name__:\n",
    "    # using torch valid choices are 'cpu' or 'cuda'\n",
    "    if parallelproj.cuda_present:\n",
    "        dev = \"cuda\"\n",
    "    else:\n",
    "        dev = \"cpu\"\n",
    "\n",
    "# Manual Override\n",
    "dev = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Parameters**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# image scale (can be used to simulated more or less counts)\n",
    "img_scale = 0.1\n",
    "# number of MLEM iterations to init. PDHG and LM-SPDHG\n",
    "num_iter_mlem = 10\n",
    "# number of PDHG iterations\n",
    "num_iter_pdhg = 3000\n",
    "# number of subsets for SPDHG and LM-SPDHG\n",
    "num_subsets = 28\n",
    "# number of iterations for stochastic PDHGs\n",
    "num_iter_spdhg = 100\n",
    "# prior weight\n",
    "beta = 10.0\n",
    "# step size ratio for LM-SPDHG\n",
    "gamma = 1.0 / img_scale\n",
    "# rho value for LM-SPHDHG\n",
    "rho = 0.9999\n",
    "# contaminaton in every sinogram bin relative to mean of trues sinogram\n",
    "contam=1.0\n",
    "\n",
    "\n",
    "# subset probabilities for SPDHG\n",
    "p_g = 0.5  # gradient update\n",
    "p_a = (1 - p_g) / num_subsets  # data subset update\n",
    "\n",
    "track_cost = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of PET data in sinogram space\n",
    "\n",
    "In this example, we use simulated listmode data for which we first\n",
    "need to setup a sinogram forward model to create a noise-free and noisy\n",
    "emission sinogram that can be converted to listmode data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of the sinogram forward model\n",
    "\n",
    "We setup a linear forward operator $A$ consisting of an\n",
    "image-based resolution model, a non-TOF PET projector and an attenuation model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_rings = 5\n",
    "scanner = parallelproj.RegularPolygonPETScannerGeometry(\n",
    "    xp,\n",
    "    dev,\n",
    "    radius=350.0,\n",
    "    num_sides=28,\n",
    "    num_lor_endpoints_per_side=16,\n",
    "    lor_spacing=4.0,\n",
    "    ring_positions=xp.linspace(-10, 10, num_rings),\n",
    "    symmetry_axis=2,\n",
    ")\n",
    "\n",
    "# setup the LOR descriptor that defines the sinogram\n",
    "\n",
    "img_shape = (40, 40, 5)\n",
    "voxel_size = (4.0, 4.0, 4.0)\n",
    "\n",
    "lor_desc = parallelproj.RegularPolygonPETLORDescriptor(\n",
    "    scanner,\n",
    "    radial_trim=170,\n",
    "    max_ring_difference=num_rings - 1,\n",
    "    sinogram_order=parallelproj.SinogramSpatialAxisOrder.RVP,\n",
    ")\n",
    "\n",
    "proj = parallelproj.RegularPolygonPETProjector(\n",
    "    lor_desc, img_shape=img_shape, voxel_size=voxel_size\n",
    ")\n",
    "\n",
    "# setup a simple test image containing a few \"hot rods\"\n",
    "x_true = xp.ones(proj.in_shape, device=dev, dtype=xp.float32)\n",
    "c0 = proj.in_shape[0] // 2\n",
    "c1 = proj.in_shape[1] // 2\n",
    "x_true[(c0 - 2) : (c0 + 2), (c1 - 2) : (c1 + 2), :] = 5.0\n",
    "x_true[4, c1, 2:] = 5.0\n",
    "x_true[c0, 4, :-2] = 5.0\n",
    "\n",
    "tmp_n = proj.in_shape[0] // 4\n",
    "x_true[:tmp_n, :, :] = 0\n",
    "x_true[-tmp_n:, :, :] = 0\n",
    "x_true[:, :2, :] = 0\n",
    "x_true[:, -2:, :] = 0\n",
    "\n",
    "# scale image to get more counts\n",
    "x_true *= img_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attenuation image and sinogram setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# setup an attenuation image\n",
    "x_att = 0.01 * xp.astype(x_true > 0, xp.float32)\n",
    "# calculate the attenuation sinogram\n",
    "att_sino = xp.exp(-proj(x_att))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete sinogram PET forward model setup\n",
    "\n",
    "We combine an image-based resolution model,\n",
    "a non-TOF or TOF PET projector and an attenuation model\n",
    "into a single linear operator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# enable TOF - comment if you want to run non-TOF\n",
    "proj.tof_parameters = parallelproj.TOFParameters(\n",
    "    num_tofbins=17, tofbin_width=12.0, sigma_tof=12.0\n",
    ")\n",
    "\n",
    "# setup the attenuation multiplication operator which is different\n",
    "# for TOF and non-TOF since the attenuation sinogram is always non-TOF\n",
    "if proj.tof:\n",
    "    att_op = parallelproj.TOFNonTOFElementwiseMultiplicationOperator(\n",
    "        proj.out_shape, att_sino\n",
    "    )\n",
    "else:\n",
    "    att_op = parallelproj.ElementwiseMultiplicationOperator(att_sino)\n",
    "\n",
    "res_model = parallelproj.GaussianFilterOperator(\n",
    "    proj.in_shape, sigma=4.5 / (2.35 * proj.voxel_size)\n",
    ")\n",
    "\n",
    "# compose all 3 operators into a single linear operator\n",
    "pet_lin_op = parallelproj.CompositeLinearOperator((att_op, proj, res_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation of sinogram projection data\n",
    "\n",
    "We setup an arbitrary ground truth $x_{true}$ and simulate\n",
    "noise-free and noisy data $y$ by adding Poisson noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# simulated noise-free data\n",
    "noise_free_data = pet_lin_op(x_true)\n",
    "\n",
    "# generate a contant contamination sinogram\n",
    "contamination = xp.full(\n",
    "    noise_free_data.shape,\n",
    "    contam * float(xp.mean(noise_free_data)),\n",
    "    device=dev,\n",
    "    dtype=xp.float32,\n",
    ")\n",
    "\n",
    "noise_free_data += contamination\n",
    "\n",
    "# add Poisson noise\n",
    "np.random.seed(1)\n",
    "d = xp.asarray(\n",
    "    np.random.poisson(np.asarray(to_device(noise_free_data, \"cpu\"))),\n",
    "    device=dev,\n",
    "    dtype=xp.int16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run quick MLEM as initialization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLEM iteration 010 / 010\r"
     ]
    }
   ],
   "source": [
    "x_mlem = xp.ones(pet_lin_op.in_shape, dtype=xp.float32, device=dev)\n",
    "# calculate A^H 1\n",
    "adjoint_ones = pet_lin_op.adjoint(\n",
    "    xp.ones(pet_lin_op.out_shape, dtype=xp.float32, device=dev)\n",
    ")\n",
    "\n",
    "for i in range(num_iter_mlem):\n",
    "    print(f\"MLEM iteration {(i + 1):03} / {num_iter_mlem:03}\", end=\"\\r\")\n",
    "    dbar = pet_lin_op(x_mlem) + contamination\n",
    "    x_mlem *= pet_lin_op.adjoint(d / dbar) / adjoint_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the cost function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def cost_function(img):\n",
    "    exp = pet_lin_op(img) + contamination\n",
    "    res = float(xp.sum(exp - d * xp.log(exp)))\n",
    "    res += beta * float(xp.sum(xp.linalg.vector_norm(op_G(img), axis=0)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDHG\n",
    "\n",
    ".. admonition:: PDHG algorithm to minimize negative Poisson log-likelihood + regularization\n",
    "\n",
    "  | **Input** Poisson data $d$\n",
    "  | **Initialize** $x,y,w,S_A,S_G,T$\n",
    "  | **Preprocessing** $\\overline{z} = z = A^T y + \\nabla^T w$\n",
    "  | **Repeat**, until stopping criterion fulfilled\n",
    "  |     **Update** $x \\gets \\text{proj}_{\\geq 0} \\left( x - T \\overline{z} \\right)$\n",
    "  |     **Update** $y^+ \\gets \\text{prox}_{D^*}^{S_A} ( y + S_A  ( A x + s))$\n",
    "  |     **Update** $w^+ \\gets \\beta \\, \\text{prox}_{R^*}^{S_G/\\beta} ((w + S_G  \\nabla x)/\\beta)$\n",
    "  |     **Update** $\\Delta z \\gets A^T (y^+ - y) + \\nabla^T (w^+ - w)$\n",
    "  |     **Update** $z \\gets z + \\Delta z$\n",
    "  |     **Update** $\\bar{z} \\gets z + \\Delta z$\n",
    "  |     **Update** $y \\gets y^+$\n",
    "  |     **Update** $w \\gets w^+$\n",
    "  | **Return** $x$\n",
    "\n",
    "See :cite:p:`Ehrhardt2019` :cite:p:`Schramm2022` for more details.\n",
    "\n",
    ".. admonition:: Proximal operator of the convex dual of the negative Poisson log-likelihood\n",
    "\n",
    " $(\\text{prox}_{D^*}^{S}(y))_i = \\text{prox}_{D^*}^{S}(y_i) = \\frac{1}{2} \\left(y_i + 1 - \\sqrt{ (y_i-1)^2 + 4 S d_i} \\right)$\n",
    "\n",
    ".. admonition:: Step sizes\n",
    "\n",
    " $S_A = \\gamma \\, \\text{diag}(\\frac{\\rho}{A 1})$\n",
    "\n",
    " $S_G = \\gamma \\, \\text{diag}(\\frac{\\rho}{|\\nabla|})$\n",
    "\n",
    " $T_A = \\gamma^{-1} \\text{diag}(\\frac{\\rho}{A^T 1})$\n",
    "\n",
    " $T_G = \\gamma^{-1} \\text{diag}(\\frac{\\rho}{|\\nabla|})$\n",
    "\n",
    " $T = \\min T_A, T_G$ pointwise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op_G = parallelproj.FiniteForwardDifference(pet_lin_op.in_shape)\n",
    "\n",
    "# initialize primal and dual variables\n",
    "x_pdhg = 1.0 * x_mlem\n",
    "y = 1 - d / (pet_lin_op(x_pdhg) + contamination)\n",
    "\n",
    "# initialize dual variable for the gradient \n",
    "w = xp.zeros(op_G.out_shape, dtype=xp.float32, device=dev)\n",
    "\n",
    "z = pet_lin_op.adjoint(y) + op_G.adjoint(w)\n",
    "zbar = 1.0 * z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# calculate PHDG step sizes\n",
    "tmp = pet_lin_op(xp.ones(pet_lin_op.in_shape, dtype=xp.float32, device=dev))\n",
    "tmp = xp.where(tmp == 0, xp.min(tmp[tmp > 0]), tmp)\n",
    "S_A = gamma * rho / tmp\n",
    "\n",
    "T_A = (\n",
    "    (1 / gamma)\n",
    "    * rho\n",
    "    / pet_lin_op.adjoint(xp.ones(pet_lin_op.out_shape, dtype=xp.float64, device=dev))\n",
    ")\n",
    "\n",
    "op_G_norm = op_G.norm(xp, dev, num_iter=100)\n",
    "S_G = gamma * rho / op_G_norm\n",
    "T_G = (1 / gamma) * rho / op_G_norm\n",
    "\n",
    "T = xp.where(T_A < T_G, T_A, xp.full(pet_lin_op.in_shape, T_G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PDHG\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PDHG iter 3000 / 3000, cost 4.9273900e+06\r"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "cost_pdhg = np.zeros(num_iter_pdhg, dtype=xp.float32)\n",
    "\n",
    "for i in range(num_iter_pdhg):\n",
    "    x_pdhg -= T * zbar\n",
    "    x_pdhg = xp.where(x_pdhg < 0, xp.zeros_like(x_pdhg), x_pdhg)\n",
    "\n",
    "    if track_cost:\n",
    "        cost_pdhg[i] = cost_function(x_pdhg)\n",
    "\n",
    "    if i == (num_iter_spdhg-1):\n",
    "        x_pdhg_early = 1.0 * x_pdhg\n",
    "\n",
    "    y_plus = y + S_A * (pet_lin_op(x_pdhg) + contamination)\n",
    "    # prox of convex conjugate of negative Poisson logL\n",
    "    y_plus = 0.5 * (y_plus + 1 - xp.sqrt((y_plus - 1) ** 2 + 4 * S_A * d))\n",
    "\n",
    "    w_plus = (w + S_G * op_G(x_pdhg)) / beta\n",
    "    # prox of convex conjugate of TV\n",
    "    denom = xp.linalg.vector_norm(w_plus, axis=0)\n",
    "    w_plus /= xp.where(denom < 1, xp.ones_like(denom), denom)\n",
    "    w_plus *= beta\n",
    "\n",
    "    delta_z = pet_lin_op.adjoint(y_plus - y) + op_G.adjoint(w_plus - w)\n",
    "    y = 1.0 * y_plus\n",
    "    w = 1.0 * w_plus\n",
    "\n",
    "    z = z + delta_z\n",
    "    zbar = z + delta_z\n",
    "\n",
    "    print(f\"PDHG iter {(i+1):04} / {num_iter_pdhg}, cost {cost_pdhg[i]:.7e}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of the emission sinogram to listmode\n",
    "\n",
    "Using :meth:`.RegularPolygonPETProjector.convert_sinogram_to_listmode` we can convert an\n",
    "integer non-TOF or TOF sinogram to an event list for listmode processing.\n",
    "\n",
    "<div class=\"alert alert-danger\"><h4>Warning</h4><p>**Note:** The created event list is \"ordered\" and should be shuffled depending on the\n",
    "    strategy to define subsets in LM-OSEM.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating LM events (2.20e+06)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nGenerating LM events ({float(xp.sum(d)):.2e})\")\n",
    "event_start_coords, event_end_coords, event_tofbins = proj.convert_sinogram_to_listmode(\n",
    "    d\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the simulated \"ordered\" LM events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "random_inds = np.random.permutation(event_start_coords.shape[0])\n",
    "event_start_coords = event_start_coords[random_inds, :]\n",
    "event_end_coords = event_end_coords[random_inds, :]\n",
    "event_tofbins = event_tofbins[random_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of the LM subset projectors and LM subset forward models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# slices that define which elements of the event list belong to each subset\n",
    "# here every \"num_subset-th element\" is used\n",
    "subset_slices_lm = [slice(i, None, num_subsets) for i in range(num_subsets)]\n",
    "\n",
    "lm_pet_subset_linop_seq = []\n",
    "\n",
    "for i, sl in enumerate(subset_slices_lm):\n",
    "    subset_lm_proj = parallelproj.ListmodePETProjector(\n",
    "        event_start_coords[sl, :],\n",
    "        event_end_coords[sl, :],\n",
    "        proj.in_shape,\n",
    "        proj.voxel_size,\n",
    "        proj.img_origin,\n",
    "    )\n",
    "\n",
    "    # recalculate the attenuation factor for all LM events\n",
    "    # this needs to be a non-TOF projection\n",
    "    subset_att_list = xp.exp(-subset_lm_proj(x_att))\n",
    "\n",
    "    # enable TOF in the LM projector\n",
    "    subset_lm_proj.tof_parameters = proj.tof_parameters\n",
    "    if proj.tof:\n",
    "        # we need to make a copy of the 1D subset event_tofbins array\n",
    "        # stupid way of doing this, but torch asarray copy doesn't seem to work\n",
    "        subset_lm_proj.event_tofbins = 1 * event_tofbins[sl]\n",
    "        subset_lm_proj.tof = proj.tof\n",
    "\n",
    "    subset_lm_att_op = parallelproj.ElementwiseMultiplicationOperator(subset_att_list)\n",
    "\n",
    "    lm_pet_subset_linop_seq.append(\n",
    "        parallelproj.CompositeLinearOperator(\n",
    "            (subset_lm_att_op, subset_lm_proj, res_model)\n",
    "        )\n",
    "    )\n",
    "\n",
    "lm_pet_subset_linop_seq = parallelproj.LinearOperatorSequence(lm_pet_subset_linop_seq)\n",
    "\n",
    "# create the contamination list\n",
    "contamination_list = xp.full(\n",
    "    event_start_coords.shape[0],\n",
    "    float(xp.reshape(contamination, -1)[0]),\n",
    "    device=dev,\n",
    "    dtype=xp.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate event multiplicity $\\mu$ for each event in the list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "events = xp.concat(\n",
    "    [event_start_coords, event_end_coords, xp.expand_dims(event_tofbins, -1)], axis=1\n",
    ")\n",
    "mu = parallelproj.count_event_multiplicity(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listmode SPDHG\n",
    "\n",
    ".. admonition:: Listmode SPDHG algorithm to minimize negative Poisson log-likelihood\n",
    "\n",
    "  | **Input** event list $N$, contamination list $s_N$\n",
    "  | **Calculate** event counts $\\mu_e$ for each $e$ in $N$\n",
    "  | **Initialize** $x,(S_i)_i,S_G,T,(p_i)_i$\n",
    "  | **Initialize list** $y_{N} = 1 - (\\mu_N /(A^{LM}_{N} x + s_{N}))$\n",
    "  | **Preprocessing** $\\overline{z} = z = {A^T} 1 - {A^{LM}_N}^T (y_N-1)/\\mu_N$\n",
    "  | **Split lists** $N$, $s_N$ and $y_N$ into $n$ sublists $N_i$, $y_{N_i}$ and $s_{N_i}$\n",
    "  | **Repeat**, until stopping criterion fulfilled\n",
    "  |     **Update** $x \\gets \\text{proj}_{\\geq 0} \\left( x - T \\overline{z} \\right)$\n",
    "  |     **Select** $i \\in \\{ 1,\\ldots,n+1\\}$ randomly according to $(p_i)_i$\n",
    "  |     **if** $i \\leq n$:\n",
    "  |         **Update** $y_{N_i}^+ \\gets \\text{prox}_{D^*}^{S_i} \\left( y_{N_i} + S_i \\left(A^{LM}_{N_i} x + s^{LM}_{N_i} \\right) \\right)$\n",
    "  |         **Update** $\\Delta z \\gets {A^{LM}_{N_i}}^T \\left(\\frac{y_{N_i}^+ - y_{N_i}}{\\mu_{N_i}}\\right)$\n",
    "  |         **Update** $y_{N_i} \\gets y_{N_i}^+$\n",
    "  |     **else:**\n",
    "  |         **Update** $w^+ \\gets \\beta \\, \\text{prox}_{R^*}^{S_G/\\beta} ((w + S_G  \\nabla x)/\\beta)$\n",
    "  |         **Update** $\\Delta z \\gets \\nabla^T (w^+ - w)$\n",
    "  |         **Update** $w \\gets w+$\n",
    "  |     **Update** $z \\gets z + \\Delta z$\n",
    "  |     **Update** $\\bar{z} \\gets z + (\\Delta z/p_i)$\n",
    "  | **Return** $x$\n",
    "\n",
    ".. admonition:: Step sizes\n",
    "\n",
    " $S_i = \\gamma \\, \\text{diag}(\\frac{\\rho}{A^{LM}_{N_i} 1})$\n",
    "\n",
    " $T_i = \\gamma^{-1} \\text{diag}(\\frac{\\rho p_i}{{A^{LM}_{N_i}}^T 1/\\mu_{N_i}})$\n",
    "\n",
    " $T = \\min_{i=1,\\ldots,n+1} T_i$ pointwise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Intialize image x with solution from quick LM OSEM\n",
    "x_lmspdhg = 1.0 * x_mlem\n",
    "\n",
    "# setup dual variable for data subsets\n",
    "ys = []\n",
    "for k, sl in enumerate(subset_slices_lm):\n",
    "    ys.append(\n",
    "        1 - (mu[sl] / (lm_pet_subset_linop_seq[k](x_lmspdhg) + contamination_list[sl]))\n",
    "    )\n",
    "\n",
    "# initialize dual variable for the gradient\n",
    "w_lm = xp.zeros(op_G.out_shape, dtype=xp.float32, device=dev)\n",
    "\n",
    "z = 1.0 * adjoint_ones\n",
    "for k, sl in enumerate(subset_slices_lm):\n",
    "    z += lm_pet_subset_linop_seq[k].adjoint((ys[k] - 1) / mu[sl])\n",
    "    # tmp = lm_pet_subset_linop_seq[k].adjoint(1 / mu[sl])\n",
    "z += op_G.adjoint(w_lm)\n",
    "zbar = 1.0 * z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the step sizes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "S_A_lm = []\n",
    "ones_img = xp.ones(img_shape, dtype=xp.float32, device=dev)\n",
    "\n",
    "for lm_op in lm_pet_subset_linop_seq:\n",
    "    tmp = lm_op(ones_img)\n",
    "    tmp = xp.where(tmp == 0, xp.min(tmp[tmp > 0]), tmp)\n",
    "    S_A_lm.append(gamma * rho / tmp)\n",
    "\n",
    "\n",
    "T_A_lm = xp.zeros((num_subsets + 1,) + pet_lin_op.in_shape, dtype=xp.float32)\n",
    "for k, sl in enumerate(subset_slices_lm):\n",
    "    tmp = lm_pet_subset_linop_seq[k].adjoint(1 / mu[sl])\n",
    "    T_A_lm[k] = (rho * p_a / gamma) / tmp\n",
    "T_A_lm[-1] = T_G\n",
    "T_lm = xp.min(T_A_lm, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run LM-SPDHG\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LM-SPDHG iter 0100 / 100, cost 4.9274000e+06\r"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "cost_lmspdhg = np.zeros(num_iter_spdhg, dtype=xp.float32)\n",
    "psnr_lmspdhg = np.zeros(num_iter_spdhg, dtype=xp.float32)\n",
    "\n",
    "psnr_scale = float(xp.max(x_true)) \n",
    "\n",
    "for i in range(num_iter_spdhg):\n",
    "    subset_sequence = np.random.permutation(2 * num_subsets)\n",
    "\n",
    "    psnr_lmspdhg[i] = 10*xp.log10((psnr_scale**2) / float(xp.mean((x_lmspdhg - x_pdhg)**2)))\n",
    "\n",
    "    if track_cost:\n",
    "        cost_lmspdhg[i] = cost_function(x_lmspdhg)\n",
    "    print(\n",
    "        f\"LM-SPDHG iter {(i+1):04} / {num_iter_spdhg}, cost {cost_lmspdhg[i]:.7e}\",\n",
    "        end=\"\\r\",\n",
    "    )\n",
    "\n",
    "    for k in subset_sequence:\n",
    "        x_lmspdhg -= T_lm * zbar\n",
    "        x_lmspdhg = xp.where(x_lmspdhg < 0, xp.zeros_like(x_lmspdhg), x_lmspdhg)\n",
    "\n",
    "        if k < num_subsets:\n",
    "            sl = subset_slices_lm[k]\n",
    "            y_plus = ys[k] + S_A_lm[k] * (\n",
    "                lm_pet_subset_linop_seq[k](x_lmspdhg) + contamination_list[sl]\n",
    "            )\n",
    "            y_plus = 0.5 * (\n",
    "                y_plus + 1 - xp.sqrt((y_plus - 1) ** 2 + 4 * S_A_lm[k] * mu[sl])\n",
    "            )\n",
    "            dz = lm_pet_subset_linop_seq[k].adjoint((y_plus - ys[k]) / mu[sl])\n",
    "            ys[k] = y_plus\n",
    "            p = p_a\n",
    "        else:\n",
    "            w_plus = (w_lm + S_G * op_G(x_lmspdhg)) / beta\n",
    "            # prox of convex conjugate of TV\n",
    "            denom = xp.linalg.vector_norm(w_plus, axis=0)\n",
    "            w_plus /= xp.where(denom < 1, xp.ones_like(denom), denom)\n",
    "            w_plus *= beta\n",
    "            dz = op_G.adjoint(w_plus - w_lm)\n",
    "            w_lm = 1.0 * w_plus\n",
    "            p = p_g\n",
    "\n",
    "        z = z + dz\n",
    "        zbar = z + (dz / p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualizations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_true_np = parallelproj.to_numpy_array(x_true)\n",
    "x_mlem_np = parallelproj.to_numpy_array(x_mlem)\n",
    "x_pdhg_np = parallelproj.to_numpy_array(x_pdhg)\n",
    "x_pdhg_early_np = parallelproj.to_numpy_array(x_pdhg_early)\n",
    "x_lmspdhg_np = parallelproj.to_numpy_array(x_lmspdhg)\n",
    "\n",
    "pl2 = x_true_np.shape[2] // 2\n",
    "pl1 = x_true_np.shape[1] // 2\n",
    "pl0 = x_true_np.shape[0] // 2\n",
    "\n",
    "fig, ax = plt.subplots(2, 5, figsize=(12, 4), tight_layout=True)\n",
    "vmax = 1.2 * x_true_np.max()\n",
    "ax[0, 0].imshow(x_true_np[:, :, pl2], cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "ax[0, 1].imshow(x_mlem_np[:, :, pl2], cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "ax[0, 2].imshow(x_pdhg_np[:, :, pl2], cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "ax[0, 3].imshow(x_lmspdhg_np[:, :, pl2], cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "ax[0, 4].imshow(x_pdhg_early_np[:, :, pl2], cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "\n",
    "ax[1, 0].imshow(x_true_np[pl0, :, :].T, cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "ax[1, 1].imshow(x_mlem_np[pl0, :, :].T, cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "ax[1, 2].imshow(x_pdhg_np[pl0, :, :].T, cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "ax[1, 3].imshow(x_lmspdhg_np[pl0, :, :].T, cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "ax[1, 4].imshow(x_pdhg_early_np[pl0, :, :].T, cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "\n",
    "ax[0, 0].set_title(\"true img\", fontsize=\"medium\")\n",
    "ax[0, 1].set_title(\"init img\", fontsize=\"medium\")\n",
    "ax[0, 2].set_title(f\"PDHG {num_iter_pdhg} it. (ref)\", fontsize=\"medium\")\n",
    "ax[0, 3].set_title(\n",
    "    f\"LM-SPDHG {num_iter_spdhg} it. / {num_subsets} subsets\", fontsize=\"medium\"\n",
    ")\n",
    "ax[0, 4].set_title(f\"PDHG {num_iter_spdhg} it.\", fontsize=\"medium\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if track_cost:\n",
    "    fig2, ax2 = plt.subplots(1, 3, figsize=(12, 4), tight_layout=True)\n",
    "    for i in range(2):\n",
    "        ax2[i].plot(cost_pdhg, \".-\", label=\"PDHG\")\n",
    "        ax2[i].plot(cost_lmspdhg, \".-\", label=\"LM-SPDHG\")\n",
    "        ax2[i].grid(ls=\":\")\n",
    "        ax2[i].legend()\n",
    "        ax2[i].set_ylim(None, cost_pdhg[10:].max())\n",
    "    ax2[1].set_xlim(0, num_iter_spdhg)\n",
    "    ax2[2].plot(psnr_lmspdhg, \".-\")\n",
    "    ax2[2].grid(ls=\":\")\n",
    "    for axx in ax2.ravel():\n",
    "        axx.set_xlabel(\"iteration\")\n",
    "    ax2[0].set_title(\"cost\", fontsize=\"medium\")\n",
    "    ax2[1].set_title(\"cost (zoom)\", fontsize=\"medium\")\n",
    "    ax2[2].set_title(\"PSNR LM-SPDHG vs ref\", fontsize=\"medium\")\n",
    "    fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
